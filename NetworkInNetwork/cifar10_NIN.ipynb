{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 ZZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "REGULARIZER  = 0.0001\n",
    "checkpoint_save_path =  './Model/NIN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入及数据增强\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "mean = [125.307, 122.95, 113.865]  #np.mean()\n",
    "std = [62.9932, 62.0887, 66.7048]  #np.std()\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "DataGenTrain = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "               rotation_range = 15,\n",
    "               width_shift_range = 0.1,\n",
    "               height_shift_range = 0.1,\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = False,\n",
    "               shear_range=0.1,\n",
    "               zoom_range = 0.1)\n",
    "DataGenTrain.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习率衰减表\n",
    "def scheduler(epoch):\n",
    "    if epoch <= 25:\n",
    "        return 0.1\n",
    "    if epoch <= 50:\n",
    "        return 0.05\n",
    "    if epoch <= 75:    \n",
    "        return 0.01\n",
    "    return 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(Model):\n",
    "    def __init__(self,channels,kernel_size,strides,padding):\n",
    "        super(ConvBNRelu,self).__init__()\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "                    Conv2D(filters=channels, kernel_size=kernel_size,strides=strides, padding=padding,\n",
    "                           kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER)),\n",
    "                    BatchNormalization(momentum=0.9),\n",
    "                    Activation('relu') ])\n",
    "    def call(self,inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络搭建及训练\n",
    "class NIN(Model):\n",
    "    def __init__(self):\n",
    "        super(NIN,self).__init__()\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=5,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=160,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=96,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(MaxPool2D(pool_size=3,strides=2,padding='same'))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=5,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(MaxPool2D(pool_size=3,strides=2,padding='same'))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=3,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=192,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(ConvBNRelu(channels=10,kernel_size=1,strides=1, padding='same'))\n",
    "        self.model.add(GlobalAveragePooling2D())\n",
    "        self.model.add(Activation('softmax'))\n",
    "\n",
    "    def call(self,inputs):\n",
    "        y = self.model(inputs)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NIN()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "log_dir = os.path.join(\"Model\",\"NIN_logs\")\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(scheduler),  #学习率衰减表\n",
    "            tf.keras.callbacks.ModelCheckpoint(     #模型保存\n",
    "                filepath = checkpoint_save_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                save_best_only = True),\n",
    "#             tf.keras.callbacks.EarlyStopping(       #早停\n",
    "#                 monitor = 'val_accuracy',\n",
    "#                 patience=15, \n",
    "#                 baseline=None),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)  #保存计算图\n",
    "]\n",
    "\n",
    "hist = model.fit(DataGenTrain.flow(x_train,y_train,batch_size=batch_size,shuffle=True),\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_test,y_test),\n",
    "                 validation_freq=1,\n",
    "                 callbacks=callbacks)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可视化\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use({'figure.figsize':(6,4)})\n",
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best result: {:.2f}%  ({}epochs)'.format(100*max(hist.history['val_accuracy']),1+hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard可视化\n",
    "#!tensorboard --logdir=./Model/NIN_logs\n",
    "#http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
