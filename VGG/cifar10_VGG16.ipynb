{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 ZZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "REGULARIZER  = 0.0005\n",
    "checkpoint_save_path =  './Model/VGG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入及数据增强\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "mean = [125.307, 122.95, 113.865]  #np.mean()\n",
    "std = [62.9932, 62.0887, 66.7048]  #np.std()\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "DataGenTrain = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "               rotation_range = 15,\n",
    "               width_shift_range = 0.1,\n",
    "               height_shift_range = 0.1,\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = False,\n",
    "               shear_range=0.1,\n",
    "               zoom_range = 0.1)\n",
    "DataGenTrain.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch <= 55:\n",
    "        return 0.1\n",
    "    if epoch <= 75:\n",
    "        return 0.05\n",
    "    if epoch <= 90:    \n",
    "        return 0.01\n",
    "    return 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(Model):\n",
    "    def __init__(self,channels,kernel_size,strides,padding):\n",
    "        super(ConvBNRelu,self).__init__()\n",
    "        self.model = Sequential([\n",
    "                                Conv2D(filters=channels, kernel_size=kernel_size,strides=strides, padding=padding,\n",
    "                                       kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER)),\n",
    "                                BatchNormalization(momentum=0.9),\n",
    "                                Activation('relu') \n",
    "                                ])\n",
    "    def call(self,inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络搭建及训练\n",
    "class VGG16(Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        self.c1 = ConvBNRelu(channels=64, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c2 = ConvBNRelu(channels=64, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.p1 = MaxPool2D(pool_size=(2,2),strides=2, padding='same')\n",
    "\n",
    "        self.c3 = ConvBNRelu(channels=128, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c4 = ConvBNRelu(channels=128, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.p2 = MaxPool2D(pool_size=(2,2), strides=2, padding='same')\n",
    "\n",
    "        self.c5 = ConvBNRelu(channels=256, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c6 = ConvBNRelu(channels=256, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c7 = ConvBNRelu(channels=256, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.p3 = MaxPool2D(pool_size=(2,2), strides=2, padding='same')   \n",
    "\n",
    "        self.c8 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c9 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c10 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.p4 = MaxPool2D(pool_size=(2,2), strides=2, padding='same')   \n",
    "\n",
    "        self.c11 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c12 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.c13 = ConvBNRelu(channels=512, kernel_size=(3, 3),strides=1, padding='same')\n",
    "        self.p5 = MaxPool2D(pool_size=(2,2), strides=2, padding='same')       \n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.f1 = Dense(4096,kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "        self.d1 = Dropout(0.5)\n",
    "        self.f2 = Dense(4096,kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b2 = BatchNormalization(momentum=0.9)\n",
    "        self.a2 = Activation('relu')\n",
    "        self.d2 = Dropout(0.5)\n",
    "        self.f3 = Dense(10,activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.p1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.p2(x)\n",
    "        x = self.c5(x)\n",
    "        x = self.c6(x)\n",
    "        x = self.c7(x)\n",
    "        x = self.p3(x)\n",
    "        x = self.c8(x)\n",
    "        x = self.c9(x)\n",
    "        x = self.c10(x)\n",
    "        x = self.p4(x)\n",
    "        x = self.c11(x)\n",
    "        x = self.c12(x)\n",
    "        x = self.c13(x)\n",
    "        x = self.p5(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.d2(x)\n",
    "        y = self.f3(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "log_dir = os.path.join(\"Model\",\"VGG16_logs\")\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "#             tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_lr=0.0001, patience=10, cooldown=0),\n",
    "            tf.keras.callbacks.ModelCheckpoint(     #模型保存\n",
    "                filepath = checkpoint_save_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                save_best_only = True),\n",
    "#             tf.keras.callbacks.EarlyStopping(       #早停\n",
    "#                 monitor = 'val_accuracy',\n",
    "#                 patience=10, \n",
    "#                 baseline=None),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)  #保存计算图\n",
    "]\n",
    "\n",
    "hist = model.fit(DataGenTrain.flow(x_train,y_train,batch_size=batch_size,shuffle=True),\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_test,y_test),\n",
    "                 validation_freq=1,\n",
    "                 callbacks=callbacks)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可视化\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use({'figure.figsize':(6,4)})\n",
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best result: 92.34%  (97epochs)\n",
    "print('best result: {:.2f}%  ({}epochs)'.format(100*max(hist.history['val_accuracy']),1+hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard可视化\n",
    "#!tensorboard --logdir=./Model/VGG16_logs\n",
    "#http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
