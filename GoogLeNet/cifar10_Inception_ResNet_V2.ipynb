{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 ZZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified : replace the stem structure with one convolutional layer, channels are divided by 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "REGULARIZER  = 0.0001\n",
    "checkpoint_save_path =  './Model/InceptionResnetV2/'\n",
    "log_dir = os.path.join(\"Model\",\"InceptionResnetV2_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入及数据增强\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "mean = [125.307, 122.95, 113.865]  #np.mean()\n",
    "std = [62.9932, 62.0887, 66.7048]  #np.std()\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "DataGenTrain = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "               rotation_range = 15,\n",
    "               width_shift_range = 0.125,\n",
    "               height_shift_range = 0.125,\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = False,\n",
    "               shear_range=0.125,\n",
    "               zoom_range = 0.125)\n",
    "DataGenTrain.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):  #HTD(-6,3)衰减\n",
    "    start = -6.0\n",
    "    end = 3.0\n",
    "    return lr / 2.0 * (1- math.tanh( (end-start)*epoch/epochs + start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(Model):\n",
    "    def __init__(self,channels,kernel_size,strides,padding):\n",
    "        super(ConvBNRelu,self).__init__()\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "                    Conv2D(filters=channels, kernel_size=kernel_size,strides=strides, padding=padding,\n",
    "                           kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER)),\n",
    "                    BatchNormalization(momentum=0.9),\n",
    "                    Activation('relu') ])\n",
    "    def call(self,inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResnetA(Model):\n",
    "    def __init__(self,channels=[32,32,32,32,48,64,384]):\n",
    "        super(InceptionResnetA,self).__init__()\n",
    "        channels=[int(i/4) for i in channels]\n",
    "        self.c1 = ConvBNRelu(channels=channels[0],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_1 = ConvBNRelu(channels=channels[1],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_2 = ConvBNRelu(channels=channels[2],kernel_size=3,strides=1, padding='same')\n",
    "        self.c3_1 = ConvBNRelu(channels=channels[3],kernel_size=1,strides=1, padding='same')\n",
    "        self.c3_2 = ConvBNRelu(channels=channels[4],kernel_size=3,strides=1, padding='same')\n",
    "        self.c3_3 = ConvBNRelu(channels=channels[5],kernel_size=3,strides=1, padding='same')\n",
    "        self.c4 =  Conv2D(filters=channels[6], kernel_size=1,strides=1, padding='same',\n",
    "                           kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "    def call(self,inputs):\n",
    "        x1 = self.c1(inputs)\n",
    "        x2_1 = self.c2_1(inputs)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x3_1 = self.c3_1(inputs)\n",
    "        x3_2 = self.c3_2(x3_1)\n",
    "        x3_3 = self.c3_3(x3_2)\n",
    "        x = tf.concat([x1,x2_2,x3_3], axis = -1)\n",
    "        y = self.c4(x)\n",
    "        outputs = self.a1(self.b1(y + inputs))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResnetB(Model):\n",
    "    def __init__(self,channels = [192,128,160,192,1152]):\n",
    "        super(InceptionResnetB,self).__init__()\n",
    "        channels=[int(i/4) for i in channels]\n",
    "        self.c1 = ConvBNRelu(channels=channels[0],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_1 = ConvBNRelu(channels=channels[1],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_2 = ConvBNRelu(channels=channels[2],kernel_size=(1,7),strides=1, padding='same')\n",
    "        self.c2_3 = ConvBNRelu(channels=channels[3],kernel_size=(7,1),strides=1, padding='same')\n",
    "        self.c3 =  Conv2D(filters=channels[4], kernel_size=1,strides=1, padding='same',\n",
    "                          kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "    def call(self,inputs):      \n",
    "        x1 = self.c1(inputs)\n",
    "        x2_1 = self.c2_1(inputs)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x2_3 = self.c2_3(x2_2)\n",
    "        x = tf.concat([x1,x2_3], axis = -1)\n",
    "        y = self.c3(x)\n",
    "        outputs = self.a1(self.b1(y + inputs))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResnetC(Model):\n",
    "    def __init__(self,channels = [192,192,224,256,2144]):\n",
    "        super(InceptionResnetC,self).__init__() \n",
    "        channels=[int(i/4) for i in channels]\n",
    "        self.c1 = ConvBNRelu(channels=channels[0],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_1 = ConvBNRelu(channels=channels[1],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_2 = ConvBNRelu(channels=channels[2],kernel_size=(1,3),strides=1, padding='same')\n",
    "        self.c2_3 = ConvBNRelu(channels=channels[3],kernel_size=(3,1),strides=1, padding='same')\n",
    "        self.c3 =  Conv2D(filters=channels[4], kernel_size=1,strides=1, padding='same',\n",
    "                          kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "    def call(self,inputs):\n",
    "        x1 = self.c1(inputs)\n",
    "        x2_1 = self.c2_1(inputs)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x2_3 = self.c2_3(x2_2)\n",
    "        x = tf.concat([x1,x2_3], axis = -1)\n",
    "        y = self.c3(x)\n",
    "        outputs = self.a1(self.b1(y + inputs))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionReduceA(Model):\n",
    "    def __init__(self,channels = [384,256,256,384]):\n",
    "        super(InceptionReduceA,self).__init__()    \n",
    "        channels=[int(i/4) for i in channels]\n",
    "        self.c1_1 = ConvBNRelu(channels=channels[0],kernel_size=3,strides=2, padding='valid')\n",
    "        self.c2_1 = ConvBNRelu(channels=channels[1],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_2 = ConvBNRelu(channels=channels[2],kernel_size=3,strides=1, padding='same')\n",
    "        self.c2_3 = ConvBNRelu(channels=channels[3],kernel_size=3,strides=2, padding='valid')\n",
    "        self.p3_1 = MaxPool2D(pool_size=3,strides=2, padding='valid')\n",
    "    def call(self,inputs):\n",
    "        x1_1 = self.c1_1(inputs)\n",
    "        x2_1 = self.c2_1(inputs)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x2_3 = self.c2_3(x2_2)\n",
    "        x3_1 = self.p3_1(inputs)\n",
    "        outputs = tf.concat([x1_1,x2_3,x3_1], axis = -1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionReduceB(Model):\n",
    "    def __init__(self,channels = [256,384,256,288,256,288,320]):\n",
    "        super(InceptionReduceB,self).__init__()       \n",
    "        channels=[int(i/4) for i in channels]\n",
    "        self.c1_1 = ConvBNRelu(channels=channels[0],kernel_size=1,strides=1, padding='same')\n",
    "        self.c1_2 = ConvBNRelu(channels=channels[1],kernel_size=3,strides=2, padding='valid')\n",
    "        self.c2_1 = ConvBNRelu(channels=channels[2],kernel_size=1,strides=1, padding='same')\n",
    "        self.c2_2 = ConvBNRelu(channels=channels[3],kernel_size=3,strides=2, padding='valid')\n",
    "        self.c3_1 = ConvBNRelu(channels=channels[4],kernel_size=1,strides=1, padding='same')\n",
    "        self.c3_2 = ConvBNRelu(channels=channels[5],kernel_size=3,strides=1, padding='same')\n",
    "        self.c3_3 = ConvBNRelu(channels=channels[6],kernel_size=3,strides=2, padding='valid')\n",
    "        self.p4_1 = MaxPool2D(pool_size=3,strides=2, padding='valid')\n",
    "    def call(self,inputs):\n",
    "        x1_1 = self.c1_1(inputs)\n",
    "        x1_2 = self.c1_2(x1_1)\n",
    "        x2_1 = self.c2_1(inputs)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x3_1 = self.c3_1(inputs)\n",
    "        x3_2 = self.c3_2(x3_1)\n",
    "        x3_3 = self.c3_3(x3_2)\n",
    "        x4_1 = self.p4_1(inputs)\n",
    "        outputs = tf.concat([x1_2,x2_2,x3_3,x4_1], axis = -1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络搭建及训练\n",
    "class InceptionResnetV2(Model):\n",
    "    def __init__(self):\n",
    "        super(InceptionResnetV2,self).__init__()\n",
    "        self.c1 = ConvBNRelu(channels=96,kernel_size=3,strides=1, padding='same')\n",
    "        self.blocks = Sequential()\n",
    "        for _ in range(5):\n",
    "            self.blocks.add(InceptionResnetA())\n",
    "        self.blocks.add(InceptionReduceA())\n",
    "        for _ in range(10):\n",
    "            self.blocks.add(InceptionResnetB())\n",
    "        self.blocks.add(InceptionReduceB())\n",
    "        for _ in range(5):\n",
    "            self.blocks.add(InceptionResnetC())\n",
    "        self.p1 = GlobalAveragePooling2D()\n",
    "        self.d1 = Dropout(0.2)\n",
    "        self.f1 = Dense(10,activation='softmax',kernel_initializer=\"he_normal\",\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))  \n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.blocks(x)\n",
    "        x = self.p1(x)\n",
    "        x = self.d1(x)\n",
    "        y = self.f1(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = InceptionResnetV2()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True, clipnorm=2.),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(scheduler),  #学习率衰减表\n",
    "            #tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_lr=0.0001, patience=10, cooldown=0)\n",
    "            tf.keras.callbacks.ModelCheckpoint(     #模型保存\n",
    "                filepath = checkpoint_save_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                save_best_only = True),\n",
    "#             tf.keras.callbacks.EarlyStopping(       #早停\n",
    "#                 monitor = 'val_accuracy',\n",
    "#                 patience=15, \n",
    "#                 baseline=None),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)  #保存计算图\n",
    "]\n",
    "\n",
    "hist = model.fit(DataGenTrain.flow(x_train,y_train,batch_size=batch_size,shuffle=True),\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_test,y_test),\n",
    "                 validation_freq=1,\n",
    "                 callbacks=callbacks)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可视化\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use({'figure.figsize':(6,4)})\n",
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard可视化\n",
    "#!tensorboard --logdir=./Model/InceptionResnetV2_logs\n",
    "#http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best result: {:.2f}%  ({}epochs)'.format(100*max(hist.history['val_accuracy']),1+hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))))\n",
    "# best result: 93.97%  (148epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
