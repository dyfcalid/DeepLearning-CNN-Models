{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 ZZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "REGULARIZER  = 0.0001\n",
    "checkpoint_save_path =  './Model/WRN/'\n",
    "log_dir = os.path.join(\"Model\",\"WRN_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入及数据增强\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "mean = [125.307, 122.95, 113.865]  #np.mean()\n",
    "std = [62.9932, 62.0887, 66.7048]  #np.std()\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "DataGenTrain = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "               rotation_range = 15,\n",
    "               width_shift_range = 0.125,\n",
    "               height_shift_range = 0.125,\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = False,\n",
    "               shear_range=0.125,\n",
    "               zoom_range = 0.125)\n",
    "DataGenTrain.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):  #HTD(-6,3)衰减\n",
    "    start = -6.0\n",
    "    end = 3.0\n",
    "    return lr / 2.0 * (1- math.tanh( (end-start)*epoch/epochs + start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideResnetBlock(Model):\n",
    "    def __init__(self,channels,k,strides,increase):\n",
    "        super(WideResnetBlock,self).__init__()\n",
    "        self.increase = increase\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "        self.c1 = Conv2D(filters=channels*k, kernel_size=3, strides=strides, padding='same',\n",
    "                         kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b2 = BatchNormalization(momentum=0.9)  \n",
    "        self.a2 = Activation('relu')\n",
    "        self.d1 = Dropout(0.3)\n",
    "        self.c2 = Conv2D(filters=channels*k, kernel_size=3, strides=1, padding='same', \n",
    "                         kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        if self.increase:\n",
    "            self.c3 = Conv2D(filters=channels*k, kernel_size=1, strides=strides, padding='same', \n",
    "                             kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = self.b1(inputs)\n",
    "        x = self.a1(x)\n",
    "        x = self.c1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.d1(x)\n",
    "        y = self.c2(x)\n",
    "        if self.increase:\n",
    "            proj = self.c3(inputs)\n",
    "        else :\n",
    "            proj = inputs\n",
    "        outputs = y + proj\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideResNet(Model):\n",
    "    def __init__(self,depth,k):\n",
    "        super(WideResNet,self).__init__()\n",
    "        N = (depth - 4)//6\n",
    "        channels = [16,16,32,64]\n",
    "        self.c1 = Conv2D(filters=channels[0], kernel_size=3, strides=1, padding='same', \n",
    "                         kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "        self.b1 = BatchNormalization(momentum=0.9)\n",
    "        self.a1 = Activation('relu')\n",
    "        self.blocks = Sequential()\n",
    "        \n",
    "        self.blocks.add(WideResnetBlock(channels=channels[1],k=k,strides=1,increase=True))\n",
    "        for _ in range(1,N):\n",
    "            self.blocks.add(WideResnetBlock(channels=channels[1],k=k,strides=1,increase=False))\n",
    "            \n",
    "        self.blocks.add(WideResnetBlock(channels=channels[2],k=k,strides=2,increase=True))\n",
    "        for _ in range(1,N):\n",
    "            self.blocks.add(WideResnetBlock(channels=channels[2],k=k,strides=1,increase=False))\n",
    "            \n",
    "        self.blocks.add(WideResnetBlock(channels=channels[3],k=k,strides=2,increase=True))\n",
    "        for _ in range(1,N):\n",
    "            self.blocks.add(WideResnetBlock(channels=channels[3],k=k,strides=1,increase=False))\n",
    "            \n",
    "        self.b2 = BatchNormalization(momentum=0.9)\n",
    "        self.a2 = Activation('relu')\n",
    "        self.p1 = GlobalAveragePooling2D()\n",
    "        self.f1 = Dense(10,activation='softmax',kernel_initializer=\"he_normal\",\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER),bias_initializer=tf.constant_initializer(0.1))\n",
    "    def call(self,inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.p1(x)\n",
    "        y = self.f1(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = WideResNet(depth=28,k=10)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True, clipnorm=2.),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(scheduler),  #学习率衰减表\n",
    "            #tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_lr=0.0001, patience=10, cooldown=0)\n",
    "            tf.keras.callbacks.ModelCheckpoint(     #模型保存\n",
    "                filepath = checkpoint_save_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                save_best_only = True),\n",
    "#             tf.keras.callbacks.EarlyStopping(       #早停\n",
    "#                 monitor = 'val_accuracy',\n",
    "#                 patience=15, \n",
    "#                 baseline=None),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)  #保存计算图\n",
    "]\n",
    "\n",
    "hist = model.fit(DataGenTrain.flow(x_train,y_train,batch_size=batch_size,shuffle=True),\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(x_test,y_test),\n",
    "                 validation_freq=1,\n",
    "                 callbacks=callbacks)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可视化\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use({'figure.figsize':(6,4)})\n",
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard可视化\n",
    "#!tensorboard --logdir=./Model/WRN_logs\n",
    "#http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best result: {:.2f}%  ({}epochs)'.format(100*max(hist.history['val_accuracy']),1+hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))))\n",
    "# best result: 94.97%  (98epochs)   16-8   Baseline \n",
    "#              95.65%  (94epochs)   28-10  without dropout\n",
    "#              95.94% （149epoch）  28-10  dropout 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
