{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 ZZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空洞卷积(DilatedConvolution)更多适用于语义分割，这里仅进行了功能实现，代替下采样\n",
    "# 借助residual结构，并将内部替换为Hybrid DilatedConvolution模块，并不断堆叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, AveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "REGULARIZER  = 0.0001\n",
    "checkpoint_save_path =  './Model/DilatedConvolution/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入及数据增强\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "mean = [125.307, 122.95, 113.865]  #np.mean()\n",
    "std = [62.9932, 62.0887, 66.7048]  #np.std()\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "DataGenTrain = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "               rotation_range = 15,\n",
    "               width_shift_range = 0.1,\n",
    "               height_shift_range = 0.1,\n",
    "               horizontal_flip = True,\n",
    "               vertical_flip = False,\n",
    "               shear_range=0.1,\n",
    "               zoom_range = 0.1)\n",
    "DataGenTest = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "DataGenTrain.fit(x_train)\n",
    "DataGenTest.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):  #HTD(-6,3)衰减\n",
    "    start = -6.0\n",
    "    end = 3.0\n",
    "    return lr / 2.0 * (1- math.tanh( (end-start)*epoch/epochs + start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNRelu(Model):\n",
    "    def __init__(self):\n",
    "        super(BNRelu,self).__init__()\n",
    "        self.bn = BatchNormalization(momentum=0.9)\n",
    "        self.relu = Activation('relu')\n",
    "    def call(self,inputs):\n",
    "        x = self.bn(inputs)\n",
    "        outputs = self.relu(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedConv(Model):\n",
    "    def __init__(self,channels,kernel_size,strides,dilation_rate,padding):\n",
    "        super(DilatedConv,self).__init__()\n",
    "        self.model = Conv2D(filters=channels, kernel_size=kernel_size,strides=strides, padding=padding,\n",
    "                           dilation_rate=dilation_rate,\n",
    "                           kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "    def call(self,inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedConvBNRelu(Model):\n",
    "    def __init__(self,channels,kernel_size,strides,dilation_rate,padding):\n",
    "        super(DilatedConvBNRelu,self).__init__()\n",
    "        self.DC = DilatedConv(channels=channels, kernel_size=kernel_size,strides=strides,dilation_rate=dilation_rate,padding=padding)\n",
    "        self.b = BNRelu()                                                 \n",
    "    def call(self,inputs):\n",
    "        x = self.DC(inputs)\n",
    "        outputs = self.b(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDilatedConv(Model):\n",
    "    def __init__(self,channels):\n",
    "        super(HybridDilatedConv,self).__init__()\n",
    "        self.HDC1 = DilatedConvBNRelu(channels=channels,kernel_size=3,strides=1,dilation_rate=1,padding='same')\n",
    "        self.HDC2 = DilatedConvBNRelu(channels=channels,kernel_size=3,strides=1,dilation_rate=2,padding='same')\n",
    "        self.HDC3 = DilatedConv(channels=channels,kernel_size=3,strides=1,dilation_rate=3,padding='same')\n",
    "        self.b = BNRelu()\n",
    "        self.c = Conv2D(filters=channels, kernel_size=1,strides=1, padding='same',\n",
    "                           kernel_initializer=\"he_normal\",kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "    def call(self,inputs):\n",
    "        x = self.HDC1(inputs)\n",
    "        x = self.HDC2(x)\n",
    "        x = self.HDC3(x)\n",
    "        outputs = self.b(x + self.c(inputs))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDCNet(Model):\n",
    "    def __init__(self):\n",
    "        super(HDCNet,self).__init__()\n",
    "        self.channels = [16,32,64,128,256]\n",
    "        self.blocks = Sequential()\n",
    "        for i in range(5):\n",
    "            self.blocks.add(HybridDilatedConv(channels=self.channels[i]))\n",
    "        self.p1 = GlobalAveragePooling2D()\n",
    "        self.f1 = Dense(10,activation='softmax',kernel_initializer=\"he_normal\",\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(REGULARIZER))\n",
    "    def call(self,inputs):\n",
    "        x = self.blocks(inputs)\n",
    "        x = self.p1(x)\n",
    "        y = self.f1(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = HDCNet()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True, clipnorm=2.),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = os.path.join(\"Model\",\"DilatedConvolution_logs\")\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(scheduler),  #学习率衰减表\n",
    "            #tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_lr=0.0001, patience=10, cooldown=0)\n",
    "            tf.keras.callbacks.ModelCheckpoint(     #模型保存\n",
    "                filepath = checkpoint_save_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                save_best_only = True),\n",
    "#             tf.keras.callbacks.EarlyStopping(       #早停\n",
    "#                 monitor = 'val_accuracy',\n",
    "#                 patience=15, \n",
    "#                 baseline=None),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)  #保存计算图\n",
    "]\n",
    "\n",
    "hist = model.fit(DataGenTrain.flow(x_train,y_train,batch_size=batch_size,shuffle=True),\n",
    "                 epochs=epochs,\n",
    "                 validation_data=DataGenTest.flow(x_test,y_test,batch_size=1000),\n",
    "                 validation_freq=1,\n",
    "                 callbacks=callbacks)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果可视化\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use({'figure.figsize':(6,4)})\n",
    "\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(hist.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard可视化\n",
    "#!tensorboard --logdir=./Model/DilatedConvolution_logs\n",
    "#http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best result: {:.2f}%  ({}epochs)'.format(100*max(hist.history['val_accuracy']),1+hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))))\n",
    "# best result: 92.58%  (95epochs)  Baseline  No residual\n",
    "#              93.22%  (86epochs)  with residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
